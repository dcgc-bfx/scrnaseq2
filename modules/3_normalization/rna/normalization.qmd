---
# Module-specific parameters (that are not already in the profile yaml)
params:
  # Name of the module used in configurations
  module: "normalization_rna"
    
  # Relative path to the module directory (which contains the qmd file)
  module_dir: "modules/3_normalization/rna"

  # Path to previous module. If null, will be read from the 'chapters' entry in the profile yaml
  prev_module_dir: null
  
  # Default assay. If null, will be set to the default assay of the input Seurat object.
  default_assay: null
  
  # For large datasets: Do not keep counts in memory but store on disk in matrix directories. Computations will access only the relevant parts of the data. Once done, matrix directories will be saved together with the Seurat object in the module directory.
  on_disk_counts: true
  
  # For large datasets: Copy matrix directories to a temporary directory for computations. This will improve performance if the temporary directory  has a better performance than normal disks (e.g. SSD). Once done, matrix directories will be copied back to the module directory. The temporary directory will be deleted once the R session exists.
  on_disk_use_tmp: true
  
  # Which normalization should be used for analysis?
  # lognorm (Seurat), scran, SCT, log (just log-transformation), identity (use raw counts)
  normalization_method: "lognorm"
  
   # Whether or not to remove cell cycle effects
  cellcycle_remove: false

  # Should all cell cycle effects be removed, or only the difference between profilerating cells (G2M and S phase)?
  # Read https://satijalab.org/seurat/v3.1/cell_cycle_vignette.html, for an explanation
  cellcycle_remove_all: true
   
  # Whether or not to re-score cell cycle effects after data
  #   from different samples have been merged/integrated
  # cc_rescore_after_merge: !r TRUE
  # NOT POSSIBLE ANYMORE HOWEVER SCALING WILL ALWAYS BE DONE ON THE SEPARATE DATASETS
  # BUT IT MAY BE POSSIBLE WHEN DOING PCA INTEGRATION

  # Additional (unwanted) variables that will be regressed out for visualisation and clustering.
  # Set to 'null' to deactivate.
  vars_to_regress: null
  
  # Which method should be used for feature selection?
  # vst (Seurat), scran or SCT
  feature_selection_method: "vst"
  
  # Number of variable features to use
  num_variable_features: 3000
  
  # Use sketch-based methods for further analyses
  use_sketching: false
  
  # Number of barcodes in sketch
  num_barcodes_for_sketching: 50000
  
  # Number of cores to use for computations
  cores: 4
  
# Module execution
execute:
  # Should this module be frozen and never re-rendered?
  # - auto: if the code has not changed (default)
  # - true/false: freeze/re-render
  # Does not apply in interactive mode or when explicitly rendering this document via in rstudio
  freeze: auto
---

# Normalization

```{r}
#| label: setup

# If running code interactively in rstudio, set profile here
# When rendering with quarto, profile is already set and should not be overwritten
if (nchar(Sys.getenv("QUARTO_PROFILE")) == 0) {Sys.setenv("QUARTO_PROFILE" = "scrnaseq")}

# Load libraries
library(knitr)
library(magrittr)
library(gt)
library(Seurat)
library(ggplot2)
library(future)
library(BiocParallel)

# Get module directory (needed to access files within the module directory)
module_dir = params$module_dir
```

```{r}
#| label: normalization_rna_preparation

# CODE
# Source general configurations (always)
source("R/general_configuration.R")

# Source required R functions
source("R/functions_util.R")
source("R/functions_io.R")
source("R/functions_plotting.R")
source("R/functions_analysis.R")

# Be verbose or not
verbose = param("verbose")

# Parallelisation config for all functions that use the future framework
plan(multisession, workers=param("cores"))

# Parallelisation config for all functions that use the BiocParallel framework
register(SnowParam(workers=param("cores"), type="SOCK", RNGseed=getOption("random_seed"))) 

# Parallelisation config for BLAS threading. Currently set to 1 because there does not seem to be a performance gain
# but may be relevant for very large projects.
RhpcBLASctl::blas_set_num_threads(1)

# DIRECTORIES
# Module directory 'results' contains all output that should be provided together with the final report of the project
dir.create(file.path(module_dir, "results"), showWarnings=FALSE)
files = list.files(path=file.path(module_dir, "results"), full.names=TRUE)
if (length(files) > 0) unlink(files, recursive=TRUE)

# Module directory 'sc' contains the final Seurat object
dir.create(file.path(module_dir, "sc"), showWarnings=FALSE)
files = list.files(path=file.path(module_dir, "sc"), full.names=TRUE)
if (length(files) > 0) unlink(files, recursive=TRUE)

# SEURAT OBJECT
# Read in seurat object
if (!is.null(param("prev_module_dir"))) {
  prev_module_dir = param("prev_module_dir")
} else {
  prev_module_dir = PreviousModuleDir(module_dir)
}
prev_sc_obj = file.path(prev_module_dir, "sc", "sc.rds")
if(!file.exists(prev_sc_obj)) {
  stop(FormatString("Could not find a sc.rds file in {prev_module_dir}. Was the respective module already run?"))
}
sc = SeuratObject::LoadSeuratRds(prev_sc_obj)

# Check that the Seurat object is okay
if (length(SeuratObject::Layers(sc)) == 0) {
  stop("No layers found in Seurat object. Please check the input object.")
}

# Set default assay standard
default_assay = param("default_assay")
if (is.null(default_assay)) default_assay = Seurat::DefaultAssay(sc)
Seurat::DefaultAssay(sc) = default_assay

# ON-DISK LAYERS (if used)
on_disk_counts = param("on_disk_counts")

# If requested, move on-disk layers to faster temp location for faster access
on_disk_use_tmp = param("on_disk_use_tmp")
if (on_disk_counts & on_disk_use_tmp) {
  on_disk_path = tempdir()
  with_progress({
    sc = UpdateMatrixDirs(sc, dir=on_disk_path)
  }, enable=verbose)
}

# CHECKS
barcode_metadata = sc[[]]

# Additional variables to be regressed out: are they in the barcode metadata?
vars_to_regress = param("vars_to_regress")
f = vars_to_regress %in% colnames(barcode_metadata)
if (!all(f)) {
  stop(FormatString("Variables to be regressed out - {vars_to_regress[!f]*} - are not in the barcode metadata. Please check the parameter 'vars_to_regress'."))
}

# Should cell cycle effects be removed? If yes, add to the variables to be regressed out
cellcycle_remove = param("cellcycle_remove")
cellcycle_remove_all = param("cellcycle_remove_all")

if (cellcycle_remove) {
  # Are they in the barcode metadata?
  f = c("Phase", "G2M.Score", "S.Score", "CC.Difference") %in% colnames(barcode_metadata)
  if (!all(f)) {
    stop("The barcode metadata does not contain all required cell cycle columns ('Phase', 'G2M.Score', 'S.Score', 'CC.Difference'). Please rerun cell cycle scoring for the Seurat object.")
  }
  
  if (cellcycle_remove_all) {
    # Remove all signal associated to cell cycle
    vars_to_regress = c(vars_to_regress, "Phase") %>% unique()
  } else {
    # Don't remove the difference between cycling and non-cycling cells 
    vars_to_regress = c(vars_to_regress, "CC.Difference") %>% unique()
  }
}

# Get image names
# At the moment an image is associated with only one assay.
# For other assays, we plot all images.
image_names = SeuratObject::Images(sc, assay=default_assay)
if (length(image_names)==0) image_names = SeuratObject::Images(sc)
```

In this section, we subsequently run a series of Seurat functions for each provided sample:

1. We start by running a **standard log normalization**, where counts for each barcode are divided by the total counts for that barcode and multiplied by 10,000. This is then natural-log transformed.

::: {.callout-tip title="What do we need normalization for?" collapse="true"}

The number of raw sequencing reads per barcode is influenced by technical differences in the capture, reverse transcription and sequencing of RNA molecules, particularly due to the difficulty of achieving consistent library preparation with minimal starting material. Thus, comparing expression between barcodes may reveal differences that are solely due to sampling effects. After low-quality barcodes were removed in the previous step, the primary goal of normalization is to remove technical sampling effects while preserving the true biological signal.

Count depth scaling is the simplest and most commonly used normalization strategy. The underlying idea is that each cell initially contained an equal number of mRNA molecules, and differences arise due to sampling effects. For each barcode, the number of reads per feature is divided by a barcode-specific “size factor”, which is proportional to the total count depth of the barcode. The resulting normalized data add up to 1 per barcode, and is then typically multiplied by a factor of 10 (10,000 in this workflow).

Finally, normalized data are log-transformed for three important reasons. First, distances between log-transformed expression data represent log fold changes. Log-transformation emphasizes contributions from features with strong relative differences, for example a gene that is expressed at an average count of 50 in cell type A and 10 in cell type B rather than a gene that is expressed at an average count of 1100 in A and 1000 in B. Second, log-transformation mitigates the relation between mean and variance in the data. Lastly, log-transformation reduces that skewness of the data as many downstream analyses require the data to be normally distributed.

:::

2. We assign **cell cycle scores** to each barcode based on its normalized expression of G2/M and S phase markers. These scores are visualised in a separate section further below. If specified in the above parameter section, cell cycle effects are removed during scaling (step 3). 

::: {.callout-tip title="How does removal of cell cycle effects affect the data?" collapse="true"}

Note that removing all signal associated to cell cycle can negatively impact downstream analysis. For example, in differentiating processes, stem cells are quiescent and differentiated cells are proliferating (or vice versa), and removing all cell cycle effects can blur the distinction between these cells. An alternative approach is to remove the difference between G2M and S phase scores. This way, signals separating non-cycling and cycling cells will be maintained, while differences amongst proliferating cells will be removed. For a more detailed explanation, see the [cell cycle vignette for Seurat](https://satijalab.org/seurat/articles/cell_cycle_vignette).

:::

3. Dependent on the normalization of your choice, we either

a. Run standard functions to select **variable features**, and **scale** normalized gene counts. For downstream analysis it is beneficial to focus on features that exhibit high cell-to-cell variation, that is they are highly expressed in some barcodes and lowly in others.

b. Run **SCTransform**, a new and more sophisticated normalization method that replaces the previous functions (**normalization, variable features and scaling**).

::: {.callout-tip title="What is **SCTransform** special about?" collapse="true"}

The standard log-transformation applied in step 1 assumes that count depth influences all features equally. However, it has been shown that the use of a single size factor will introduce different effects on highly and lowly expressed features @Hafemeister_2019. **SCTransform** is a new statistical approach for the modelling, normalization and variance stabilization of single-cell RNA-seq data, and is an alternative to steps 1 and 3a described above. Note that **SCTransform** has been developed for UMI count data and can therefore safely be applied to 10x but not SmartSeq-2 data. As for the scaling in step 3a, additional unwanted sources of variations can be regressed out during **SCTransform**.

:::

While raw data is typically used for statistical tests such as finding marker features, normalized data is mainly used for visualising expression values. Scaled data include variable features only, potentially without cell cycle effects, and are mainly used to determine the structure of the dataset(s) with Principal Component Analysis, and indirectly to cluster and visualise barcodes in 2D space.

## Run Normalization

```{r}
#| label: normalization_rna_normalize
#| results: asis

# Run normalization

normalization_method = param("normalization_method")
num_variable_features = param("num_variable_features")
layer_counts = SeuratObject::Layers(sc, assay=default_assay, search="^counts\\.")
layer_data = gsub(pattern="^counts", replacement="data", x=layer_counts)

# Do normalization
if (normalization_method == "lognorm") {
  # Run log normalization
  sc = Seurat::NormalizeData(sc, 
                             normalization.method="LogNormalize", 
                             verbose=verbose,
                             layer=layer_counts,
                             save=layer_data)
  
  CalloutBox("Seurat log normalization was applied.", type="note")
  
} else if(normalization_method == "scran") {
  # Run scran normalization
  with_progress({
    sc = NormalizeDataScran(sc, 
                            layer=layer_counts, 
                            save=layer_data,
                            chunk_size=50000)
  }, enable=verbose)
  
  CalloutBox("Scran normalization was applied.")
  
} else if(normalization_method == "SCT") {
  # Run SCTransform normalization
  sct_assay_name = paste0(default_assay, "sct")
  sc = SCTransform(sc,
                   assay=Seurat::DefaultAssay(sc),
                   new.assay.name=sct_assay_name,
                   vst.flavor="v2",
                   variable.features.n=num_variable_features,
                   vars.to.regress=vars_to_regress,
                   return.only.var.genes=TRUE,
                   verbose=verbose,
                   seed.use=getOption("random_seed"),
                   conserve.memory=length(Cells(sc[[default_assay]])) >= 100000)
  Seurat::DefaultAssay(sc) = sct_assay_name

  CalloutBox("SCTransform normalization was applied.", type="note")
} else if (normalization_method == "log") {
  # Run log transformation (just log, no size factors)
  sc = TransformData(sc, 
                     log=TRUE, 
                     layer=layer_counts,
                     save=layer_data)
  
  CalloutBox("Log transformation was applied.", type="note")
} else if (normalization_method == "identity") {
  # Run identity transformation (keep raw counts)
  sc = TransformData(sc,
                     log=FALSE,
                     layer=layer_counts,
                     save=layer_data)
  
  CalloutBox("No normalization/transformation was applied.", type="note")
}


# Convert queued operations into real data and write to disk
if (on_disk_counts) {
  
  if (normalization_method != "SCT") {
    # For methods lognorm, scran, log and identity we need to write all 'data' layers to disk
  
    layers = SeuratObject::Layers(sc, assay=default_assay, search="^counts\\.") %>% 
      gsub(pattern="counts", replacement="data", x=.)
    for(i in seq_along(layers)) {
      # Get IterableMatrix object
      mat = SeuratObject::LayerData(sc, assay=default_assay, layer=layers[i])
      
      # Write data to disk
      matrix_dir = WriteCounts_MatrixDir(counts=mat,
                                         path=file.path(on_disk_path, paste(default_assay, layers[i], sep=".")),
                                         overwrite=TRUE)
      
      # Load into Seurat object
      SeuratObject::LayerData(sc, assay=default_assay, layer=layers[i]) = matrix_dir
    }
    
  } else {
    # The SCT assay is not Seurat v5 compatible and therefore does not support on-disk counts.
    # It produces no layers but only a 'counts', a 'data' and a 'scale.data' slot.
  }
}
```

To better understand the efficiency of the applied normalization procedures, we plot the relative log expression of features in randomly selected subset of barcodes per sample before and after normalization. This type of plot reveals unwanted variation in your data. The concept is taken from @Gandolfo_2018. In brief, we remove variation between features, leaving only variation between samples. If expression levels of most features are similar in all cell types, sample heterogeneity is a sign of unwanted variation.

For each feature, we calculate its median expression across all barcodes, and then calculate the deviation from this median for each barcode. For each barcode, we plot the median expression (black), the interquartile range (<span style="color:lightgrey;font-weight:bold">lightgrey</span>), whiskers defined as 1.5 times the interquartile range (<span style="color:darkgrey;font-weight:bold">darkgrey</span>), and outliers (`r paste0('<span style="color:', unname(ScColours(sc, "orig.ident")), ';font-weight:bold">', unname(ScColours(sc, "orig.ident")), '</span>', collapse=', ')`)

::: panel-tabset

##### Raw counts

```{r}
#| label: fig-normalization_rna_rle_plot_raw
#| fig-cap: "Relative log expression plot for raw counts"

# Plot relative log expression

normalization_method = param("normalization_method")

# Do relative log expression plots
p = PlotRLE(sc, layer="counts", is_log=FALSE)
p
```

##### Normalized counts

```{r}
#| label: fig-normalization_rna_rle_plot_normalized
#| fig-cap: "Relative log expression plot for normalized counts"

# Plot relative log expression

normalization_method = param("normalization_method")

# Do relative log expression plots
p = PlotRLE(sc, layer="data", is_log=TRUE)
p
```

:::

## Variable features

Experience shows that 1,000-2,000 features with the highest cell-to-cell variation are often sufficient to describe the global structure of a single-cell dataset. For example, cell type-specific genes typically highly vary between cells. Housekeeping genes, on the other hand, are similarly expressed across cells and can be disregarded to differentiate between cells. Highly variable genes are typically the genes with a cell type specific expression profile, and are often the genes of interest in single-cell experiments. Housekeeping genes, with similar levels of expression across all cells, or genes with minor expression differences, might add random noise and mask relevant changes during downstream dimensionality reduction and clustering. We therefore aim to select a sensible set of variable genes that includes interesting biological signal and excludes noise. 

::: {.callout-tip title="How are variable genes selected?" collapse="true"}

To determine variable genes, we need to separate biological variability from technical variability. Technical variability arises especially for lowly expressed genes, where high variability corresponds to small absolute changes that we are not interested in. Here, we use the variance-stabilizing transformation (vst) method implemented in Seurat @Hafemeister_2019. This method first models the technical variability as a relationship between mean gene expression and variance using local polynomial regression. The model is then used to calculate the expected variance based on the observed mean gene expression. The difference between the observed and expected variance is called residual variance and likely reflects biological variability.

:::

```{r}
#| label: normalization_rna_variable_features
#| results: asis

# Find variable features

normalization_method = param("normalization_method")
feature_selection_method = param("feature_selection_method")
num_variable_features = param("num_variable_features")

# Identify variable features
# Runs methods 'vst' or 'scran', method 'SCT' was already done when running SCTransform
if(normalization_method != "SCT" & feature_selection_method != "SCT") {
  sc = FindVariableFeaturesWrapper(sc, 
                                   feature_selection_method=feature_selection_method,
                                   num_variable_features=num_variable_features,
                                   verbose=verbose)
}

CalloutBox("The {feature_selection_method} method was used to select {num_variable_features} variable features.", type="note")
```

```{r}
#| label: normalization_rna_variable_features_plots
#| results: asis

# Plot variable features

if (feature_selection_method == "SCT") {
  plist = PlotVariableFeatures(sc, 
                     method="sct",
                     assay=paste0(default_assay, "sct"),
                     top=10)
} else {
  plist = PlotVariableFeatures(sc, 
                     method=feature_selection_method,
                     assay=default_assay,
                     top=10)
}

# Make captions
orig_idents = gsub(pattern="varFeatures_", replacement="", x=names(plist))
captions = GeneratePlotCaptions("varFeatures", assay_names=SeuratObject::Assays(sc)) %>% paste("for dataset {orig_idents}") %>% FormatString()

# Generate chunks
chunk_template = "
##### {{name}}

\`\`\`{r}
#| label: fig-normalization_rna_variable_features_{{name}}
#| fig-cap: {{caption}}
#| echo: false
#| warning: false

plist[[{{i}}]]
\`\`\`
"

cat("::: panel-tabset\n")

for (i in seq(plist)) {
  chunk_filled =  knitr::knit_expand(text=chunk_template, name=orig_idents[i], i=i, caption=captions[i])
  if(interactive()) {
    print(EvalKnitrChunk(chunk_filled))
  } else {
    chunk_filled = knitr::knit_child(text=chunk_filled, envir=environment(), quiet=TRUE)
    cat(chunk_filled, sep='\n')
  }
}
cat(":::\n")

```

## Scale data

To be able to compare normalized gene counts between genes, gene counts are further scaled to have zero mean and unit variance (z-score).

::: {.callout-tip title="What do we need scaling for?" collapse="true}

After normalization, gene expression data can be compared between cells. However, expression of individual genes still cannot be compared. This is because genes have different lengths and, depending on the experimental set up, longer genes can be represented by a higher number of reads. To account for this effect, normalized data are further scaled using a z-transformation, resulting in the average expression of 0 and the variance of 1 for each gene across all cells. Note that additional unwanted sources of variations can be regressed out during the scaling process, such as cell cycle effects or the percentage of mitochondrial reads.

:::

```{r}
#| label: normalization_rna_scale_data
#| results: asis

# Scale data for variable features
use_sketching = param("use_sketching")
normalization_method = param("normalization_method")
bcs = SeuratObject::Cells(sc[[default_assay]])
barcode_metadata = sc[[]][bcs, ]

# Not needed if:
# a) SCTransform since it already scaled data
# b) when applying sketching since we only scale the data of the sketch
if(normalization_method != "SCT" & !use_sketching) {
  
  # Unfortunately ScaleData has limited support for on-disk counts
  # Therefore we load the normalized data into memory, run ScaleData and 
  # then extract the scale.data layer.
  if (on_disk_counts) {
    # Keep layers with normalized data but convert to sparse matrix
    var_features = VariableFeatures(sc, assay=default_assay)
    normalized_layers = SeuratObject::Layers(sc, assay=default_assay, search="data")
    normalized_data = purrr::map(normalized_layers, function(n) {
      ldat = SeuratObject::LayerData(sc, layer=n, assay=default_assay, features=var_features)
      ldat = as(ldat, "dgCMatrix")
      return(ldat)
    })
    names(normalized_data) = normalized_layers

    # Create Seurat v5 assay object
    normalized_data = SeuratObject::CreateAssay5Object(data=normalized_data)
    
    # Get data for vars_to_regress
    if (any(vars_to_regress %in% colnames(barcode_metadata))) {
      keep = vars_to_regress %in% colnames(barcode_metadata)
      latent_data = barcode_metadata[vars_to_regress[keep]]
    } else {
      latent_data = NULL
    }
    
    # Run ScaleData
    normalized_data = Seurat::ScaleData(normalized_data, vars.to.regress=vars_to_regress, latent.data=latent_data, verbose=verbose)
    
    # Add scale.data layer to Seurat object
    SeuratObject::LayerData(sc, assay=default_assay, layer="scale.data") = SeuratObject::LayerData(normalized_data, layer="scale.data")
    rm(normalized_data)
    invisible(gc())
  } else {
    # Run ScaleData
    sc = Seurat::ScaleData(sc, verbose=verbose, vars.to.regress=vars_to_regress)
  }
}

if (length(vars_to_regress) > 0) {
  # Print a message
  CalloutBox("The following variables were regressed out during scaling of the data: {vars_to_regress*}.", type="note")
}
```

## Sketching

Depending on the size of the data, it may not possible anymore to run the downstream analyses on the full dataset. In this case, we can now use sketching to reduce the dataset size. Sketching is a technique that allows to approximate the full dataset with a smaller subset of cells. This is done by randomly selecting a subset of cells and then running the downstream analyses on this subset. The results are then extrapolated to the full dataset. 

```{r}
#| label: normalization_rna_sketching
#| results: asis

# Prepare sketching

normalization_method = param("normalization_method")
feature_selection_method = param("feature_selection_method")
num_variable_features = param("num_variable_features")
num_barcodes = length(SeuratObject::Cells(sc[[default_assay]]))
use_sketching = param("use_sketching")
num_barcodes_for_sketching = param("num_barcodes_for_sketching")

# Create a sketch assay (subset) of num_barcodes_for_sketching barcodes for sketch
if (use_sketching) {
  # Note that it does not work to sketch an SCT assay. Rather sketch based on the assay that 
  # was used as input for SCT and then rerun SCTRansform on the sketch.
  
  # Create a sketch of the data
  # Method can be: LeverageScore or Uniform. LeverageScore is better but slower.
  sketched_assay_name = paste0(default_assay, "sketch")
  sc = Seurat::SketchData(sc,
                          assay=default_assay,
                          ncells=num_barcodes_for_sketching,
                          sketched.assay=sketched_assay_name,
                          verbose=verbose,
                          method="LeverageScore",
                          seed=getOption("random_seed"),
                          over.write=TRUE)
  
  # Set search key for features of the sketch assay
  sketched_assay_key = sketched_assay_name %>% 
    gsub(pattern="\\.", replacement="", x=.) %>%
    tolower()
  sketched_assay_key = paste0(sketched_assay_key, "_")
  SeuratObject::Key(sc[[sketched_assay_name]]) = sketched_assay_key
  
  # Set sketch assay as default assay
  SeuratObject::DefaultAssay(sc) = sketched_assay_name
  
  # SCTransform normalization needs to be repeated for the sketch
  if(normalization_method == "SCT") {
    sketched_sct_assay_name = paste0(default_assay, "sctsketch")
    sc = SCTransform(sc,
                     assay=sketched_assay_name,
                     new.assay.name=sketched_sct_assay_name,
                     vst.flavor="v2",
                     variable.features.n=num_variable_features,
                     vars.to.regress=vars_to_regress,
                     return.only.var.genes=TRUE,
                     verbose=verbose,
                     seed.use=getOption("random_seed"))
    
    # Set search key for features of the SCT-normalized sketch assay
    sketched_sct_assay_key = sketched_sct_assay_name %>% 
      gsub(pattern="\\.", replacement="", x=.) %>%
      tolower()
    sketched_sct_assay_key = paste0(sketched_sct_assay_key, "_")
    SeuratObject::Key(sc[[sketched_sct_assay_name]]) = sketched_sct_assay_key
    
    # Set sketched and SCT normalized assay as default assay
    Seurat::DefaultAssay(sc) = sketched_sct_assay_name

    # Drop original sketched assay
    sc[[sketched_assay_name]] = NULL
  }
  
  # Find variable features for sketch; this is already done when running SCTransform
  # Also scale data
  if(normalization_method != "SCT") {
    sc = FindVariableFeaturesWrapper(sc,
                                     feature_selection_method=feature_selection_method,
                                     num_variable_features=num_variable_features,
                                     verbose=verbose)
    sc = Seurat::ScaleData(sc, verbose=verbose, vars.to.regress=vars_to_regress)
  }

  # Print sketched assay
  CalloutBox(paste("Sketching was applied using a subset of", num_barcodes_for_sketching, "barcodes."), type="note")
  knitr::knit_print(sc)

  # Finally reset default assay to non-sketched assay
  SeuratObject::DefaultAssay(sc) = ifelse(normalization_method=="SCT", 
                                          paste0(default_assay, "sct"), 
                                          default_assay)
} else {
  CalloutBox("Sketching was not applied.", type="note")
}
```

## Software

```{r}
#| label: normalization_rna_save_software

sessioninfo = ScrnaseqSessionInfo(getwd()) %>% as.data.frame()
gt(sessioninfo)
```

## Parameter

```{r}
#| label: read_data_save_parameter  

paraminfo = ScrnaseqParamsInfo(param()) %>% as.data.frame()
gt(paraminfo)
```

```{r}
#| label: normalization_rna_save_seurat

# Save Seurat object and layer data
# Note: counts and normalized data have been changed in this module, copying needed
outdir = file.path(module_dir, "sc")
with_progress({
  SaveSeuratRdsWrapper(sc,
                       outdir=outdir,
                       write_disk_data=on_disk_counts,
                       relative_paths=FALSE,
                       compress=FALSE
                       )
}, enable=verbose)
```

```{r}
#| label: normalization_rna_finish

# Stop multisession workers
plan(sequential)
```
