---
# Module-specific parameters (that are not already in the profile yaml)
params:
  # Name of the module used in configurations
  module: "dimensionality_reduction_rna"
    
  # Relative path to the module directory (which contains the qmd file)
  module_dir: "modules/4_dimensionality_reduction/rna"

  # Path to previous module. If null, will be read from the 'chapters' entry in the profile yaml
  prev_module_dir: null
  
  # Default assay. If null, will be set to the default assay of the input Seurat object.
  default_assay: null
  
  # For large datasets: Do not keep counts in memory but store on disk in matrix directories. Computations will access only the relevant parts of the data. Once done, matrix directories will be saved together with the Seurat object in the module directory.
  on_disk_counts: true
  
  # For large datasets: Copy matrix directories to a temporary directory for computations. This will improve performance if the temporary directory  has a better performance than normal disks (e.g. SSD). Once done, matrix directories will be copied back to the module directory. The temporary directory will be deleted once the R session exists.
  on_disk_use_tmp: true
  
  # Which normalization should be used for analysis? Can we read from seurat object
  # lognorm (Seurat), scran or SCT
  normalization_method: "SCT"
  
  # Which dimensionality reduction to use: only PCA supported
  dimensionality_reduction_method: "PCA"
  
  # Number of dimensions (e.g. principal components) to compute
  dim_n_compute: 50
  
  # Number of dimensions (e.g. principal components) to use
  dim_n: 10

  # Use sketch-based integration methods for analysis
  use_sketching: false
  
  # One or more integration method(s) to use. 
  # The following methods are available: null (just merge), CCAIntegration, RPCAIntegration, HarmonyIntegration , FastMNNIntegration, scVIIntegration.
  integration_methods: null

  # Parameters for CCAIntegration
  CCAIntegration: null
  
  # Parameters for RPCAIntegration
  RPCAIntegration: null
  
  # Parameters for HarmonyIntegration
  HarmonyIntegration: null
  
  # Parameters for FastMNNIntegration
  FastMNNIntegration: null
  
  # Parameters for scVIIntegration.
  scVIIntegration: null
  
  # Number of cores to use for computations
  cores: 4
    
# Module execution
execute:
  # Should this module be frozen and never re-rendered?
  # - auto: if the code has not changed (default)
  # - true/false: freeze/re-render
  # Does not apply in interactive mode or when explicitly rendering this document via in rstudio
  freeze: "auto"
---

# Dimensionality reduction

```{r}
#| label: setup

# If running code interactively in rstudio, set profile here
# When rendering with quarto, profile is already set and should not be overwritten
if (nchar(Sys.getenv("QUARTO_PROFILE")) == 0) {Sys.setenv("QUARTO_PROFILE" = "scrnaseq")}

# Load libraries
library(knitr)
library(magrittr)
library(gt)
library(Seurat)
library(SeuratWrappers)
library(ggplot2)
library(future)
library(patchwork)

# Get module name and directory (needed to access files within the module directory)
module_name = params$module_name
module_dir = params$module_dir
```

```{r}
#| label: dimensionality_reduction_rna_preparation

# CODE
# Source general configurations (always)
source("R/general_configuration.R")

# Source required R functions
source("R/functions_util.R")
source("R/functions_io.R")
source("R/functions_plotting.R")
source("R/functions_analysis.R")

# Be verbose or not
verbose = param("verbose")

# Parallelisation plan for all functions that support future
plan(multisession, workers=param("cores"))

# DIRECTORIES
# Module directory 'results' contains all output that should be provided together with the final report of the project
dir.create(file.path(module_dir, "results"), showWarnings=FALSE)
files = list.files(path=file.path(module_dir, "results"), full.names=TRUE)
if (length(files) > 0) unlink(files, recursive=TRUE)

# Module directory 'sc' contains the final Seurat object
dir.create(file.path(module_dir, "sc"), showWarnings=FALSE)
files = list.files(path=file.path(module_dir, "sc"), full.names=TRUE)
if (length(files) > 0) unlink(files, recursive=TRUE)

# SEURAT OBJECT
# Read in seurat object
if (!is.null(param("prev_module_dir"))) {
  prev_module_dir = param("prev_module_dir")
} else {
  prev_module_dir = PreviousModuleDir(module_dir)
}
prev_sc_obj = file.path(prev_module_dir, "sc", "sc.rds")
if(!file.exists(prev_sc_obj)) {
  stop(FormatString("Could not find a sc.rds file in {{prev_module_dir}}. Was the respective module already run?"))
}
sc = SeuratObject::LoadSeuratRds(prev_sc_obj)

# Move on-disk layers to faster temp location if requested
on_disk_counts = param("on_disk_counts")
on_disk_use_tmp = param("on_disk_use_tmp")

if (on_disk_counts & on_disk_use_tmp) {
  on_disk_path = tempdir()
  with_progress({
    sc = UpdateMatrixDirs(sc, dir=on_disk_path)
  }, enable=verbose)
} else {
  on_disk_path = file.path(module_dir, "sc")
}

# Set default assay standard
default_assay = param("default_assay")
if (is.null(default_assay)) default_assay = Seurat::DefaultAssay(sc)
Seurat::DefaultAssay(sc) = default_assay

# If sketching should be used, check for the sketch assay and then set as default
use_sketching = param("use_sketching")
if (use_sketching) {
  sketched_assay_name = paste(Seurat::DefaultAssay(sc), "sketch", sep=".")
  if (!sketched_assay_name %in% SeuratObject::Assays(sc)) {
    stop(FormatMessage("The option 'use_sketching' is set to true but the sketch assay {sketched_assay_name} was not found."))
  }
  SeuratObject::DefaultAssay(sc) = sketched_assay_name
}
```

A single-cell dataset of 20,000 genes and 5,000 cells has 20,000 dimensions. At this point of the analysis, we have already reduced the dimensionality of the dataset to 3,000 variable genes. The biological manifold however can be described by far fewer dimensions than the number of (variable) genes, since expression profiles of different genes are correlated if they are involved in the same biological process. Dimension reduction methods aim to find these dimensions. There are two general purposes for dimension reduction methods: to **summarize** a dataset, and to **visualize** a dataset.

## PCA

We use Principal Component Analysis (PCA) to **summarize** a dataset, overcoming noise and reducing the data to its essential components. Later, we use Uniform Manifold Approximation and Projection (UMAP) to **visualize** the dataset, placing similar cells together in 2D space, see below.

::: {.callout-tip title="PCA in a nutshell" collapse="true"}

Principal Component Analysis is a way to summarize a dataset and to reduce noise by averaging similar gene expression profiles. The information for correlated genes is compressed into single dimensions called principal components (PCs) and the analysis identifies those dimensions that capture the largest amount of variation. This process gives a more precise representation of the patterns inherent to complex and large datasets.

In a PCA, the first PC captures the greatest variance across the whole dataset. The next PC captures the greatest remaining amount of variance, and so on. This way, the top PCs are likely to represent the biological signal where multiple genes are affected by the same biological processes in a coordinated way. In contrast, random technical or biological noise that affects each gene independently are contained in later PCs. Downstream analyses can be restricted to the top PCs to focus on the most relevant biological signal and to reduce noise and unnecessary computational overhead.

:::

To decide how many PCs to include in downstream analyses, we visualize the cells and genes that define the PCA.

```{r}
#| label: dimensionality_reduction_rna_run

normalization_method = param("normalization_method")
dimensionality_reduction_method = param("dimensionality_reduction_method")
dim_n_compute = param("dim_n_compute")

# Run dimensionality reduction
sc = RunDimRedWrapper(sc, 
                      method=dimensionality_reduction_method, 
                      dim_n=dim_n_compute, 
                      verbose=verbose)

# Save original reduction
original_reduct = DefaultReduct(sc)

if (use_sketching) {
  # Project to full dataset if sketching was used
  full_reduct = paste(original_reduct, "full", sep="_")
  sc = Seurat::ProjectData(sc, 
                           assay=default_assay,
                           sketched.assay=Seurat::DefaultAssay(sc),
                           sketched.reduction=original_reduct,
                           full.reduction=full_reduct,
                           normalization.method	= ifelse(grepl("_SCT", Seurat::DefaultAssay(sc)), "SCT", "LogNormalize"),
                           dims=1:dim_n_compute)
  SeuratObject::Key(sc[[full_reduct]]) = paste0(stringr::str_to_title(original_reduct), "Full_")
  DefaultReduct(sc, assay=default_assay) = full_reduct
}
```

```{r}
#| label: fig-dimensionality_reduction_rna_loadings
#| fig-cap: "Loadings of the dimensionality reduction"
#| fig-height: 4

# When sketching is used, not available for the full dataset

# Plot loadings for first and second dimension
plist = Seurat::VizDimLoadings(sc, reduction=DefaultReduct(sc), dims=1:2, combine=FALSE, balanced=TRUE)
for (i in seq(plist)) {
  plist[[i]] = plist[[i]] + 
    AddPlotStyle()
}

plist[[1]] + plist[[2]]
```

```{r}
#| label: fig-dimensionality_reduction_rna_dim_dimensions
#| fig-cap: !expr paste("Barcodes arranged by the first two dimensions ", ifelse(use_sketching, "for the sketched dataset", ""))

# Plot the first two dimensions of the computed dimensionality reduction
p = Seurat::DimPlot(sc, 
                    reduction=DefaultReduct(sc), 
                    cols=ScColours(sc, "orig.ident")) +
  AddPlotStyle()
p
```

```{r}
#| label: fig-dimensionality_reduction_rna_dim_dimensions_full
#| fig-cap: "Barcodes arranged by the first two dimensions projected to the full dataset"
#| eval: !expr use_sketching
#| include: !expr use_sketching

# Only when sketching is used: plot the first two dimensions projected to the full dataset
if (use_sketching) {
  p = Seurat::DimPlot(sc, 
                      reduction=DefaultReduct(sc, assay=default_assay), 
                      cols=ScColours(sc, "orig.ident")) +
    AddPlotStyle()
  print(p)
}
```

```{r}
#| label: fig-dimensionality_reduction_rna_loadings_heatmaps
#| fig-cap: "Top gene loadings of the first dimensions"
#| fig-subcap: ""
#| echo: false
#| layout-ncol: 3
#| fig-height: 3
#| fig-width: 2.6

# When sketching is used, not available for the full dataset
dim_n_compute = param("dim_n_compute")

# Plot loading for the top 20 dimensions
plist = Seurat::DimHeatmap(sc, 
                           reduction=DefaultReduct(sc),
                           dims=1:min(min(20, dim_n_compute), ncol(sc)), 
                           cells=min(500, ncol(sc)),
                           balanced=TRUE, 
                           fast=FALSE, 
                           combine=FALSE)

for (i in seq(plist)) {
  plist[[i]] = plist[[i]] +
    AddPlotStyle(title=paste("Dim", i)) +
    theme(legend.position="none") +
    viridis::scale_fill_viridis() +
    theme(axis.text.x=element_blank(),
          axis.ticks=element_blank())

  print(plist[[i]])
}
```

```{r}
#| label: dimensionality_reduction_rna_loadings_spatial
#| eval: !expr length(SeuratObject::Images(sc)) > 0
#| include: !expr length(SeuratObject::Images(sc)) > 0
#| results: asis

# When sketching is used, not available for the full dataset
dimensionality_reduction_method = param("dimensionality_reduction_method")
dim_n_compute = param("dim_n_compute")
dim_features = stringr::str_to_title(dimensionality_reduction_method) %>% 
    paste0("_", 1:min(min(20, dim_n_compute), ncol(sc)))

# Set up layout for generating chunks
chunk_template = "
\`\`\`{r}
#| label: fig-dimensionality_reduction_rna_loadings_spatial_dim{{dim}}_dataset_{{dataset}}
#| fig-cap: {{caption}}

plist[['{{dataset}}']]
\`\`\`
"
  
# Iterate over dimensions
cat("::: panel-tabset\n\n")
for(dim in 1:min(min(20, dim_n_compute), ncol(sc))) {
  dim_feature = stringr::str_to_title(dimensionality_reduction_method) %>% paste0("_", dim)
  cat("##### Dim", dim, "\n\n")

  # Plot as spatial plots
  plist = FeaturePlotSpatial(sc, features=dim_feature, combine=FALSE) %>% purrr::flatten()
  plist = purrr::map(plist, function(p) {
    p =  p + theme(legend.title=element_blank())
    p = p + viridis::scale_fill_viridis()
    return(p)
  })
  names(plist) = SeuratObject::Images(sc) %>% gsub("^(fov|image)\\.", "", .)
    
  # Fill out and print spatial plots
  cat("::: panel-tabset\n\n")
  for(dataset in names(plist)) {
    cat ("#####", dataset, "\n\n")
    chunk_filled =  knitr::knit_expand(text=chunk_template, dim=dim, dataset=dataset, caption=FormatString("Loadings for dimension {dim} for dataset {dataset}"))
    if(interactive()) {
      print(EvalKnitrChunk(chunk_filled))
    } else {
      chunk_filled = knitr::knit_child(text=chunk_filled, envir=environment(), quiet=TRUE)
      cat(chunk_filled, '\n')
    }
  }
  cat(":::\n\n")
}
cat(":::\n\n")
```

## Dimensionality of the dataset

We next need to decide how many PCs we want to use for our analyses. PCs include biological signal as well as noise, and we need to determine the number of PCs with which we include as much biological signal as possible and as little noise as possible. The following "Elbow plot" is designed to help us make an informed decision. It shows PCs ranked based on the percentage of variance they explain.

::: {.callout-tip title="How do we determine the number of PCs for downstream analysis?" collapse="true"}

The top PC captures the greatest variance across cells and each subsequent PC represents decreasing levels of variance. By visual inspection of the Elbow plot, we try to find the point at which we can explain most of the variance across cells. Commonly, the top 10 PCs are chosen. It may be helpful to repeat downstream analyses with a different number of PCs, although the results often do not differ dramatically. Note that it is recommended to rather choose too many than too few PCs.

:::

```{r}
#| label: fig-dimensionality_reduction_rna_elbow_plot
#| fig-cap: "Variance explained by computed dimensions"
#| fig-cap-location: "top"

# When sketching is used, not available for the full dataset

dim_n_compute = param("dim_n_compute")
dim_n = param("dim_n")


# Plot the variance explained for the computed components
p = Seurat::ElbowPlot(sc, reduction=DefaultReduct(sc), ndims=min(dim_n_compute, ncol(sc))) + 
  geom_vline(xintercept=dim_n + .5, col="firebrick", lty=2) + 
  AddPlotStyle() 
p
```

::: callout-note
For the current dataset, `r param("dim_n")` dimensions were chosen.
:::

## Integration

Integration of multiple samples is an optional step in single-cell RNA-seq analysis. It may be necessary to remove batch effects and to enable the comparison of cells across different samples. We can use a number of methods for integration:

-   Canonical Correlation Analysis (CCA)
-   Reciprocal PCA (RPCA)
-   Harmony
-   FastMNN
-   scVI

Methods might perform differently depending on the dataset and the biological question. We can use multiple methods and compare the results. For an overview of integration methods, please see [here](https://www.nature.com/articles/s41592-021-01336-8).

```{r}
#| label: dimensionality_reduction_rna_run_integration
#| results: asis

# Get integration methods and their parameters
integration_methods = param("integration_methods")
integration_methods_params = purrr::map(integration_methods, function(method) {
  par_lst = param(method)
  
  # Parse into argument name and value. Interpret values (still strings) as R code.
  if (!is.null(par_lst)) {
    par_lst = stringr::str_split(par_lst, pattern="=", n=2)
    nms = purrr::map(par_lst, 1)
    vls = purrr::map(par_lst, 2)
    vls = purrr::map(vls, function(v) return(eval(parse(text=v))))
    par_lst = setNames(vls, nms)
  }
  return(par_lst)
})
names(integration_methods_params) = integration_methods

# Number of datasets
if (grepl(pattern="_SCT", x=default_assay)) {
  num_datasets = sc[[default_assay]]@SCTModel.list %>% length()
} else {
  num_datasets = SeuratObject::Layers(sc, assay=default_assay, search="^counts") %>% length()
}

# Run all integrations
first_reduct = NULL
if (length(integration_methods) > 0 & num_datasets > 1) {
  # Integration requested and necessary
  
  # Note: Seurat::RPCAIntegration is bugged. 
  # IntegrateLayersWrapper will use RPCAIntegration_Fixed which is a copy from the Seurat develop branch where the bug is already solved.
  
  # Note: Seurat::scVIIntegration is bugged,
  # IntegrateLayersWrapper will use scVIIntegration_Fixed which is a copy from the Seurat develop branch where the bug is already solved.

  # Integrate
  for(method in integration_methods) {
    # Call wrapper
    sc = IntegrateLayersWrapper(sc=sc,
                                integration_method=method,
                                orig_reduct=DefaultReduct(sc),
                                additional_args=integration_methods_params[[method]],
                                verbose=verbose)
    
    # If sketching was used, project integrated dimensionality reduction of sketch to full dataset
    if (use_sketching) {
      reduct = DefaultReduct(sc)
      full_reduct = paste(reduct, "full", sep="_")
      sc = Seurat::ProjectIntegration(sc,
                                      sketched.assay=SeuratObject::DefaultAssay(sc), 
                                      assay=default_assay,
                                      reduction=reduct,
                                      reduction.name=full_reduct,
                                      reduction.key=paste0(stringr::str_to_title(reduct), "Full_"),
                                      seed=getOption("random_seed"),
                                      verbose=verbose)
      DefaultReduct(sc, assay=default_assay) = full_reduct
    }
    
    # We need to make sure that the default reduction is set to the first integrated dimensionality reduction method
    if (is.null(first_reduct)) {
      # First method: keep
      first_reduct = DefaultReduct(sc)
    } else {
      # Other methods: reset
      DefaultReduct(sc) = first_reduct
      if (use_sketching) {
        DefaultReduct(sc, assay=default_assay) = paste("full", first_reduct, sep="_")
      }  
    }
  }
  
  # Message
  CalloutBox("Datasets have been integrated with the following methods: {integration_methods*}!", type="note")
  
} else if (length(integration_methods) == 0 & num_datasets > 1) {
  # Integration not requested (just merge)
  CalloutBox("Datasets are simply merged and no integration is done!", type="note")
  
} else if (num_datasets == 1) {
  # Integration not necessary
  CalloutBox("There is only one dataset so that integration is not neccessary.", type="note")
}

# Join layers if not SCT (SCT does not use layers)
# Dataset layers are automatically dropped unless there is only one dataset (in which case we need to do it)
if (!grepl(pattern="_SCT", x=default_assay)) {
  layer_counts = SeuratObject::Layers(sc, search="counts")
  layer_data = SeuratObject::Layers(sc, search="data")
  
  sc = SeuratObject::JoinLayers(sc)
  if (length(layer_counts) == 1) SeuratObject::LayerData(sc, layer=layer_counts) = NULL
  if (length(layer_data) == 1) SeuratObject::LayerData(sc, layer=layer_data) = NULL
}

# If SCTransform was run:
# - SCTransform analyses each dataset separately thereby creating models that are used to correct the dataset.
# - In the SCT assay, counts and data are still only corrected within the datasets but not between the datasets.
#   Counts and data are only valid if all datasets have the same sequencing depth.
# - If not, PrepSCTFindMarkers needs to be run which does a joint normalization using a geometric mean (similar to DESeq2).
# - https://github.com/dcgc-bfx/scrnaseq2/issues/37 and https://github.com/satijalab/seurat/issues/6675
if (grepl(pattern="_SCT", x=default_assay)) {
    sc = PrepSCTFindMarkers(sc, assay=default_assay, verbose=verbose)
    
    # If sketching was used, also apply to sketch
    if (use_sketching) {
        sketched_assay_name = paste(Seurat::DefaultAssay(sc), "sketch", sep=".")
        sc = PrepSCTFindMarkers(sc, assay=sketched_assay_name, verbose=verbose)
    }
}
```

```{r}
#| label: dimensionality_reduction_rna_integration_plots
#| results: asis
#| eval: !expr length(integration_methods) > 0 & num_datasets > 1
#| include: !expr length(integration_methods) > 0 & num_datasets > 1
#| echo: false


# Plot different integration methods
reductions = dplyr::case_match(integration_methods,
                                   "CCAIntegration" ~ "cca",
                                   "RPCAIntegration" ~ "rpca",
                                   "HarmonyIntegration" ~ "harmony",
                                   "FastMNNIntegration" ~ "mnn",
                                   "scVIIntegration" ~ "scvii",
                               TRUE ~ "NA")

plist = purrr::map(reductions, function(method) {
  title = SeuratObject::Misc(sc[[method]], slot="title")

  # Plot
  p = Seurat::DimPlot(sc, 
                      reduction=method, 
                      cols=ScColours(sc, "orig.ident")) +
    AddPlotStyle(legend_position="none")
  return(p)
})

# Add merge case (no integration)
p = Seurat::DimPlot(sc, 
                    reduction=original_reduct, 
                    cols=ScColours(sc, "orig.ident")) +
  AddPlotStyle(legend_position="none")
plist = c(list(p), plist)
names(plist) = c("merge", reductions)
captions = c("No integration", paste('Integrated with method', integration_methods))


# Generate chunks
chunk_template = "
\`\`\`{r}
#| label: fig-dimensionality_reduction_rna_integration_{{type}}
#| fig-cap: {{caption}}
#| fig-width: 4
#| fig-height: 4

plist[[{{i}}]]
\`\`\`
"

cat("Here are the resulting dimensionality reductions after integration:\n\n")

cat("::: {layout-ncol=2}\n")

for (i in seq(plist)) {
  chunk_filled =  knitr::knit_expand(text=chunk_template, type=names(plist)[i], i=i, caption=captions[i])
  if(interactive()) {
    print(EvalKnitrChunk(chunk_filled))
  } else {
    chunk_filled = knitr::knit_child(text=chunk_filled, envir=environment(), quiet=TRUE)
    cat(chunk_filled, sep='\n')
  }
}
cat(":::\n")

```

## Output

### Dimensionality reduction

```{r}
#| label: dimensionality_reduction_rna_save_reduction
#| results: asis

# Default reduction
default_reduct = DefaultReduct(sc)
reduct = sc[[default_reduct]]@cell.embeddings %>% as.data.frame()

# Write default reduction for default assay
outfile = paste0("reduction_", default_assay, "_", default_reduct , ".xlsx")
openxlsx::write.xlsx(x=reduct, file=file.path(module_dir, "results", outfile), row.names=TRUE)

# Note
CalloutBox("The default reduction {default_reduct} for the default assay {default_assay} is written to {outfile}.", type="note")
```

## Software

```{r}
#| label: dimensionality_reduction_rna_save_software

sessioninfo = ScrnaseqSessionInfo(getwd()) %>% as.data.frame()
gt(sessioninfo)
```

## Parameter

```{r}
#| label: read_data_save_parameter  

paraminfo = ScrnaseqParamsInfo(param()) %>% as.data.frame()
gt(paraminfo)
```

```{r}
#| label: dimensionality_reduction_rna_save_seurat

# If sketching was used, revert back to non-sketched assay
if (use_sketching) {
  SeuratObject::DefaultAssay(sc) = default_assay
}

# This will overwrite the (bugged) function SeuratObject::SaveSeuratRds with the content of our function SaveSeuratRds_Fixed
assignInNamespace("SaveSeuratRds",SaveSeuratRds_Fixed, ns="SeuratObject")

# Save Seurat object and layer data
with_progress({
  SaveSeuratRdsWrapper(sc,
                       on_disk_layers=on_disk_counts,
                       outdir=file.path(module_dir, "sc"))
}, enable=verbose)

```

```{r}
#| label: dimensionality_reduction_rna_finish

# Stop multisession workers
plan(sequential)
```
