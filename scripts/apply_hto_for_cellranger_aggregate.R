#!/usr/bin/env Rscript

options(stringsAsFactors=FALSE)

# Get arguments from commandline
arguments = commandArgs(trailingOnly=FALSE)

# Path to script
script_index = grep("--file", arguments)
script_dir = dirname(sub("--file=", "", arguments[script_index]))
script_dir = normalizePath(script_dir)
script_name = basename(sub("--file=", "", arguments[script_index]))

# Which packages are needed
library(knitr)
suppressPackageStartupMessages(library("argparse"))

# Prepare parser for arguments
parser = ArgumentParser(
  add_help=TRUE,
  prog=script_name,
  description="After demultiplexing of individual samples with the with the scrnaseq_hto workflow, this script applies the by-sample results to the merged dataset produced by cellranger aggregate.",
  epilog="Demultiplexing by sample has to be run first and the results must be in a subdirectory 'demultiplexed'. The script will then read the metadata.tsv.gz files per sample and adjust the cell barcodes suffixes (e.g. '-1' will become '-2' for the second sample) in the cellranger aggregate results accordingly. It will also update the CSV file with the cell identities for import into the Loupe Cell Browser. Important: The script needs to be run in the same directory as cellranger aggregate!")

parser$add_argument(c("--aggregate-results"), action="store", help="Path to an outs directory generated by cellranger aggregate", dest="aggregate_results", default=".")
parser$add_argument(c("--path-to-git"),  action="store", help="Path to the scrnaseq git repository (default: %default)", default=dirname(script_dir), dest="path_to_git")
parser$add_argument(c("--verbose"),  action="store_true", help="Be verbose (default: %default)", default=TRUE, dest="verbose")
opt = parser$parse_args()

# Source io functions from the git repository
path_to_git = opt[["path_to_git"]]
if (!file.exists(path_to_git)) stop("Could not find the git directory provided by --path-to-git!")
if (!file.exists(file.path(path_to_git, "R", "functions_io.R"))) stop("Git directory provided by --path-to-git does not contain R/functions_io.R!")
source(file.path(path_to_git, "R", "functions_io.R"))

# Check that cellranger aggregate outs directory exists
aggregate_results = opt[["aggregate_results"]]
if (!file.exists(aggregate_results)) stop("Could not find the directory provided by --aggregate-results!")
aggregate_results = normalizePath(aggregate_results)

# Check that it contains an aggregation.csv file
aggregate_csv = file.path(aggregate_results, "aggregation.csv")
if (!file.exists(aggregate_csv)) stop("Could not find the file aggregation.csv in the directory provided by --aggregate-results!")

# Read aggregation.csv
aggregate_paths = read.table(aggregate_csv, header=TRUE, sep=",")
#aggregate_paths = read.table("outs/aggregation.csv", header=TRUE, sep=",")
aggregate_paths$dir = dirname(as.character(aggregate_paths$molecule_h5))

# Create output dir
path_out = file.path(aggregate_results, "count", "demultiplexed")
if (!file.exists(path_out)) dir.create(path_out)
path_out = normalizePath(path_out)

# Get cell assignments, adjust cell index and also add another column which includes HTO and dataset name
cells_htos = list()
k = 0
for (i in seq(nrow(aggregate_paths))) {
  dataset_name = basename(dirname(aggregate_paths$dir[i]))
  
  if (file.exists(file.path(aggregate_paths$dir[i], "demultiplexed"))) {
    # Dataset was demultiplexed
    sub_dirs = dir(file.path(aggregate_paths$dir[i], "demultiplexed"), full.names=TRUE, recursive=FALSE)
    is_valid_sub_dir = sapply(sub_dirs, function(d) return(file.exists(file.path(d, "metadata.tsv.gz"))), USE.NAMES=FALSE)
    sub_dirs = sub_dirs[is_valid_sub_dir]
  } else {
    # Dataset was not demultiplexed
    sub_dirs = file.path(aggregate_paths$dir[i], "filtered_feature_bc_matrix")
  }
  
  for (j in seq(length(sub_dirs))) {
    k = k + 1
    if (file.exists(file.path(sub_dirs[j], "metadata.tsv.gz")))  {
      # Metadata available (dataset was demultiplexed)
      cells_htos[[k]] = read.table(file.path(sub_dirs[j], "metadata.tsv.gz"), header=TRUE, sep="\t")
      cells_htos[[k]]$HTO_classification_dataset = paste(cells_htos[[k]]$HTO_classification, dataset_name, sep=".")
    } else {
      # Metadata not available (dataset was not demultiplexed)
      cells_htos[[k]] = read.table(file.path(sub_dirs[j], "barcodes.tsv.gz"), header=FALSE, sep="\t")
      cells_htos[[k]] = cells_htos[[k]][, 1, drop=FALSE]
      colnames(cells_htos[[k]]) = c("CELL_ID_METADATA")
      cells_htos[[k]]$HTO_classification = "None"
      cells_htos[[k]]$HTO_hash_ID = "None"
      cells_htos[[k]]$HTO_classification_dataset = dataset_name
    }
    cells_htos[[k]]$CELL_ID_METADATA = paste(gsub("-\\d+$", "", cells_htos[[k]]$CELL_ID_METADATA), i, sep="-")
  }
}
names(cells_htos) = sapply(cells_htos, function(d) return(d[1, "HTO_classification_dataset"]))

# Now read dataset counts done by cellranger aggregate
all_counts = Seurat::Read10X(file.path(aggregate_results, "count", "filtered_feature_bc_matrix"))
all_counts_feature_table = read.table(file.path(aggregate_results, "count", "filtered_feature_bc_matrix", "features.tsv.gz"), header=FALSE, sep="\t")

# Drop the hash tag features (and the assay if empty)
for (a in names(all_counts)) {
  is_hashtag = grepl("HashTag", rownames(all_counts[[a]]), ignore.case=TRUE)
  all_counts[[a]] = all_counts[[a]][!is_hashtag, ]
}
is_empty = unlist(sapply(all_counts, nrow) == 0)
all_counts = all_counts[!is_empty]

is_hashtag = grepl("HashTag", all_counts_feature_table[, 1])
all_counts_feature_table = all_counts_feature_table[!is_hashtag, ]

# Combine remaining assays
all_counts = do.call(rbind, all_counts)

# Split by HTO and dataset
for(n in names(cells_htos)) {
  cell_barcodes = cells_htos[[n]]$CELL_ID_METADATA
  
  # Make the directory
  d = file.path(path_out, n)
  dir.create(d, showWarnings=FALSE)
  
  # Collect assay data and write
  feature_data = all_counts[, cell_barcodes]
  mh = file.path(d, "matrix.mtx")
  Matrix::writeMM(feature_data, file=mh)
  R.utils::gzip(mh, overwrite=TRUE)
  
  # Collect cell barcodes and write
  bh = gzfile(file.path(d, "barcodes.tsv.gz"), open="wb")
  write(cell_barcodes, file=bh)
  close(bh)
  
  # Write feature data
  fh = gzfile(file.path(d, "features.tsv.gz"), open="wb")
  write.table(all_counts_feature_table, file=fh, row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")
  close(fh)
  
  # Write cell metadata
  metah = gzfile(file.path(d, "metadata.tsv.gz"), open="wb")
  write.table(cells_htos[[n]], file = metah, row.names=FALSE, col.names=TRUE, quote=TRUE, sep="\t")
  close(metah)
}

# Write cell classification file for Loupe (also add not demultiplexed cells)
cells_htos_df = do.call(rbind, cells_htos)
rownames(cells_htos_df) = NULL
col_nms = colnames(cells_htos_df)
col_nms[1] = "Barcode"
colnames(cells_htos_df) = col_nms

all_cell_barcodes = colnames(all_counts)
missing_cell_barcodes_df = data.frame(Barcode=all_cell_barcodes[!all_cell_barcodes %in% cells_htos_df$Barcode],
           HTO_classification = "Negative_Doublet",
           HTO_hash_ID = "Negative_Doublet",
           HTO_classification_dataset = "Negative_Doublet")

p = file.path(path_out, "cell_classification_for_loupe.csv")
write.table(x=rbind(cells_htos_df, missing_cell_barcodes_df), file=p, col.names=TRUE, row.names=FALSE, quote=FALSE, sep=",")
